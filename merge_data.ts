#!/usr/bin/env bun

/**
 * Merge Data - Gá»™p táº¥t cáº£ data theo thá»© tá»± thá»i gian
 */

import * as fs from 'fs';
import * as path from 'path';

interface Transaction {
    digest: string;
    timestampMs: string;
    checkpoint: string;
    events: any[];
}

interface DataPage {
    cursor: string;
    nextCursor: string | null;
    data: Transaction[];
}

async function mergeData() {
    console.log('ğŸ”„ Merging All Data');
    console.log('===================\n');

    const poolId = '0x737ec6a4d3ed0c7e6cc18d8ba04e7ffd4806b726c97efd89867597368c4d06a9';

    const dataDirs = [
        { dir: `./data_historical/${poolId}`, prefix: 'historical_', label: 'Historical' },
        { dir: `./data_30_days/${poolId}`, prefix: '30day_', label: '30-Day' },
    ];

    const allTransactions: Transaction[] = [];
    let totalFiles = 0;
    let totalEvents = 0;

    // Äá»c táº¥t cáº£ data tá»« cÃ¡c thÆ° má»¥c
    for (const { dir, prefix, label } of dataDirs) {
        if (!fs.existsSync(dir)) {
            console.log(`ğŸ“ ${label}: Directory not found - ${dir}`);
            continue;
        }

        const files = fs.readdirSync(dir)
            .filter(f => f.startsWith(prefix))
            .sort();

        if (files.length === 0) {
            console.log(`ğŸ“ ${label}: No files found`);
            continue;
        }

        console.log(`ğŸ“ ${label}: Processing ${files.length} files...`);

        let processedFiles = 0;
        let skippedFiles = 0;

        for (const file of files) {
            const filePath = path.join(dir, file);

            try {
                const content: DataPage = JSON.parse(fs.readFileSync(filePath, 'utf-8'));

                if (content.data && Array.isArray(content.data)) {
                    allTransactions.push(...content.data);
                    totalEvents += content.data.reduce((sum, tx) => sum + tx.events.length, 0);
                    processedFiles++;
                } else {
                    console.log(`   âš ï¸  Skipping ${file}: Invalid data structure`);
                    skippedFiles++;
                }
            } catch (error) {
                console.log(`   âŒ Skipping ${file}: JSON parse error - ${error.message}`);
                skippedFiles++;
                continue;
            }
        }

        totalFiles += processedFiles;
        console.log(`   âœ… Processed: ${processedFiles} files, âš ï¸  Skipped: ${skippedFiles} files`);
    }

    console.log(`\nğŸ“Š Data Summary:`);
    console.log(`   ğŸ“ Total files processed: ${totalFiles}`);
    console.log(`   ğŸ“„ Total transactions: ${allTransactions.length.toLocaleString()}`);
    console.log(`   ğŸ“Š Total events: ${totalEvents.toLocaleString()}`);

    if (allTransactions.length === 0) {
        console.log('âŒ No data found to merge');
        return;
    }

    // Sáº¯p xáº¿p theo thá»i gian
    console.log('\nğŸ”„ Sorting by timestamp...');
    allTransactions.sort((a, b) => {
        const timeA = parseInt(a.timestampMs);
        const timeB = parseInt(b.timestampMs);
        return timeA - timeB;
    });

    // Loáº¡i bá» duplicates dá»±a trÃªn digest
    console.log('ğŸ”„ Removing duplicates...');
    const uniqueTransactions = new Map<string, Transaction>();

    for (const tx of allTransactions) {
        if (!uniqueTransactions.has(tx.digest)) {
            uniqueTransactions.set(tx.digest, tx);
        }
    }

    const finalTransactions = Array.from(uniqueTransactions.values());
    const finalEvents = finalTransactions.reduce((sum, tx) => sum + tx.events.length, 0);

    console.log(`ğŸ“Š After deduplication:`);
    console.log(`   ğŸ“„ Unique transactions: ${finalTransactions.length.toLocaleString()}`);
    console.log(`   ğŸ“Š Unique events: ${finalEvents.toLocaleString()}`);
    console.log(`   ğŸ—‘ï¸  Duplicates removed: ${(allTransactions.length - finalTransactions.length).toLocaleString()}`);

    // Chia thÃ nh files vá»›i 200 events má»—i file
    console.log('\nğŸ’¾ Creating merged files...');
    const outputDir = './data_merged';

    if (!fs.existsSync(outputDir)) {
        fs.mkdirSync(outputDir, { recursive: true });
    }

    const eventsPerFile = 200;
    let currentBatch: Transaction[] = [];
    let currentEventCount = 0;
    let fileCounter = 1;
    let totalSavedEvents = 0;

    for (const transaction of finalTransactions) {
        const transactionEventCount = transaction.events.length;

        // Náº¿u thÃªm transaction nÃ y sáº½ vÆ°á»£t quÃ¡ limit, lÆ°u batch hiá»‡n táº¡i
        if (currentEventCount + transactionEventCount > eventsPerFile && currentBatch.length > 0) {
            await saveMergedBatch(currentBatch, fileCounter, currentEventCount, outputDir);
            totalSavedEvents += currentEventCount;
            fileCounter++;
            currentBatch = [];
            currentEventCount = 0;
        }

        currentBatch.push(transaction);
        currentEventCount += transactionEventCount;
    }

    // LÆ°u batch cuá»‘i cÃ¹ng
    if (currentBatch.length > 0) {
        await saveMergedBatch(currentBatch, fileCounter, currentEventCount, outputDir);
        totalSavedEvents += currentEventCount;
    }

    // Thá»‘ng kÃª cuá»‘i cÃ¹ng
    const timeRange = {
        start: new Date(parseInt(finalTransactions[0].timestampMs)).toISOString(),
        end: new Date(parseInt(finalTransactions[finalTransactions.length - 1].timestampMs)).toISOString()
    };

    console.log('\nğŸ‰ Merge Complete!');
    console.log('==================');
    console.log(`ğŸ“ Output directory: ${outputDir}`);
    console.log(`ğŸ“„ Merged files: ${fileCounter}`);
    console.log(`ğŸ“Š Total events: ${totalSavedEvents.toLocaleString()}`);
    console.log(`ğŸ“… Time range: ${timeRange.start} to ${timeRange.end}`);
    console.log(`ğŸ’¾ Average events/file: ${(totalSavedEvents / fileCounter).toFixed(0)}`);

    // Táº¡o metadata file
    const metadata = {
        created: new Date().toISOString(),
        totalFiles: fileCounter,
        totalTransactions: finalTransactions.length,
        totalEvents: totalSavedEvents,
        timeRange,
        sources: dataDirs.map(d => d.label),
        eventsPerFile
    };

    fs.writeFileSync(
        path.join(outputDir, 'metadata.json'),
        JSON.stringify(metadata, null, 2)
    );

    console.log('ğŸ“‹ Metadata saved: ./data_merged/metadata.json');
}

async function saveMergedBatch(transactions: Transaction[], batchNumber: number, eventCount: number, outputDir: string): Promise<void> {
    const fileName = `merged_${String(batchNumber).padStart(5, '0')}.json`;
    const filePath = path.join(outputDir, fileName);

    const page: DataPage = {
        cursor: `merged_${batchNumber}`,
        nextCursor: null,
        data: transactions
    };

    try {
        const jsonContent = JSON.stringify(page, null, 2);
        fs.writeFileSync(filePath, jsonContent, 'utf-8');
        console.log(`   ğŸ’¾ Saved: ${fileName} (${transactions.length} transactions, ${eventCount} events)`);
    } catch (error) {
        console.error(`   âŒ Error saving ${fileName}:`, error);
    }
}

if (import.meta.main) {
    mergeData().catch(console.error);
}
