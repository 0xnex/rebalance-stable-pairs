#!/usr/bin/env bun

/**
 * Fetch Data - Optimized command for collection
 */

import { SuiEventFetcher, EventType } from './src/sui_event_fetcher';

async function fetch30Days() {
    console.log('ğŸ“… Fetching Data');
    console.log('========================\n');

    const poolId = '0x7aa448e4e16d5fde0e1f12ca26826b5bc72921bea5067f6f12fd7e298e2655f9';

    // ngÃ y tá»« hiá»‡n táº¡i
    const now = Date.now();
    const thirtyDaysAgo = now - (365 * 24 * 60 * 60 * 1000);

    console.log('ğŸ“… Collection Config:');
    console.log(`   ğŸ“… Start: ${new Date(thirtyDaysAgo).toISOString()}`);
    console.log(`   ğŸ“… End: ${new Date(now).toISOString()}`);
    console.log(`   ğŸ¯ Pool: ${poolId}`);
    console.log(`   ğŸ“Š Events: Swap + AddLiquidity + RemoveLiquidity + RepayFlashSwap + CreatePool + OpenPosition`);
    console.log(`   ğŸ“¦ Batch: 1000 events/request (optimized)`);
    console.log(`   ğŸ“ Files: 200 events/file`);
    console.log(`   âš¡ Delay: 10ms (fast)`);
    console.log('');

    const fetcher = new SuiEventFetcher({
        rpcUrl: 'https://fullnode.mainnet.sui.io:443',
        poolId: poolId,
        eventTypes: [
            EventType.Swap,
            EventType.AddLiquidity,
            EventType.RemoveLiquidity,
            EventType.RepayFlashSwap,
            EventType.CreatePool,
            EventType.OpenPosition
        ],
        startTime: thirtyDaysAgo,
        endTime: now,
        batchSize: 1000,
        outputDir: `./data/${poolId}`,
        filePrefix: `data_${poolId}_`
    });

    const startTime = Date.now();

    try {
        console.log('ğŸš€ Starting collection...');
        console.log('âš ï¸  This will take several hours. Progress will be logged.\n');

        const pages = await fetcher.fetchAllEvents();

        const duration = (Date.now() - startTime) / 1000;

        // Count results
        const fs = require('fs');
        const outputDir = `./data/${poolId}`;
        let fileCount = 0;
        let totalEvents = 0;
        let totalSize = 0;

        if (fs.existsSync(outputDir)) {
            const files = fs.readdirSync(outputDir).filter((f: string) => f.startsWith(`data_${poolId}_`));
            fileCount = files.length;

            for (const file of files) {
                const filePath = `${outputDir}/${file}`;
                const stats = fs.statSync(filePath);
                totalSize += stats.size;

                const content = JSON.parse(fs.readFileSync(filePath, 'utf-8'));
                totalEvents += content.data.reduce((sum: number, tx: any) => sum + tx.events.length, 0);
            }
        }

        console.log('\nğŸ‰ Collection Complete!');
        console.log('==============================');
        console.log(`â±ï¸  Total Duration: ${(duration / 3600).toFixed(1)} hours`);
        console.log(`ğŸ“Š Total Events: ${totalEvents.toLocaleString()}`);
        console.log(`ğŸ“ Total Files: ${fileCount.toLocaleString()}`);
        console.log(`ğŸ’¾ Total Size: ${(totalSize / 1024 / 1024 / 1024).toFixed(2)} GB`);
        console.log(`ğŸš€ Average Speed: ${(totalEvents / duration).toFixed(0)} events/sec`);
        console.log(`ğŸ“ Output Directory: ${outputDir}`);

        // Performance summary
        console.log('\nğŸ“ˆ Performance Summary:');
        console.log('======================');
        console.log(`ğŸ“Š Events/hour: ${((totalEvents / duration) * 3600).toLocaleString()}`);
        console.log(`ğŸ“ Files/hour: ${((fileCount / duration) * 3600).toFixed(0)}`);
        console.log(`ğŸ’¾ GB/hour: ${((totalSize / 1024 / 1024 / 1024 / duration) * 3600).toFixed(2)}`);

        if (totalEvents > 0) {
            console.log(`ğŸ“ˆ Average events/file: ${(totalEvents / fileCount).toFixed(0)}`);
            console.log(`ğŸ“ˆ Average file size: ${(totalSize / fileCount / 1024).toFixed(1)} KB`);
        }

    } catch (error) {
        const partialDuration = (Date.now() - startTime) / 1000;
        console.error('\nâŒ Collection failed:', error);
        console.log(`â±ï¸  Partial duration: ${(partialDuration / 3600).toFixed(1)} hours`);

        // Check partial results
        const fs = require('fs');
        const outputDir = `./data/${poolId}`;
        if (fs.existsSync(outputDir)) {
            const files = fs.readdirSync(outputDir).filter((f: string) => f.startsWith(`data_${poolId}_`));
            console.log(`ğŸ“ Partial files saved: ${files.length}`);
            console.log('ğŸ’¡ You can resume collection or use partial data');
        }
    }
}

if (import.meta.main) {
    fetch30Days().catch(console.error);
}
