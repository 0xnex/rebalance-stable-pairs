#!/usr/bin/env bun

/**
 * Fetch Future Data - Láº¥y data má»›i tá»« sau data hiá»‡n táº¡i Ä‘áº¿n hiá»‡n táº¡i
 */

import { SuiEventFetcher, EventType } from './src/sui_event_fetcher';
import * as fs from 'fs';
import * as path from 'path';

async function fetchFuture() {
    console.log('ğŸ”® Fetching Future Data');
    console.log('=======================\n');

    const poolId = '0x737ec6a4d3ed0c7e6cc18d8ba04e7ffd4806b726c97efd89867597368c4d06a9';

    // TÃ¬m timestamp má»›i nháº¥t tá»« data Ä‘Ã£ cÃ³
    const existingDataDir = './data_30_days';
    let newestTimestamp = 0;

    console.log('ğŸ” Analyzing existing data...');

    if (fs.existsSync(existingDataDir)) {
        const files = fs.readdirSync(existingDataDir)
            .filter(f => f.startsWith('30day_'))
            .sort()
            .reverse(); // Sort descending Ä‘á»ƒ láº¥y file má»›i nháº¥t

        if (files.length > 0) {
            console.log(`ğŸ“ Found ${files.length} existing files`);

            // Äá»c file cuá»‘i cÃ¹ng Ä‘á»ƒ tÃ¬m timestamp má»›i nháº¥t
            const lastFile = path.join(existingDataDir, files[0]);
            const lastContent = JSON.parse(fs.readFileSync(lastFile, 'utf-8'));

            if (lastContent.data && lastContent.data.length > 0) {
                // TÃ¬m timestamp lá»›n nháº¥t trong file cuá»‘i cÃ¹ng
                const timestamps = lastContent.data.map((tx: any) => parseInt(tx.timestampMs));
                newestTimestamp = Math.max(...timestamps);

                console.log(`ğŸ“… Newest existing data: ${new Date(newestTimestamp).toISOString()}`);
            }
        } else {
            console.log('ğŸ“ No existing data found');
            return;
        }
    } else {
        console.log('ğŸ“ No existing data directory found');
        return;
    }

    const now = Date.now();
    const futureStartTime = newestTimestamp + (60 * 1000); // ThÃªm 1 phÃºt Ä‘á»ƒ trÃ¡nh overlap

    console.log('\nğŸ”® Future Collection Config:');
    console.log(`   ğŸ“… Start: ${new Date(futureStartTime).toISOString()} (After existing data)`);
    console.log(`   ğŸ“… End: ${new Date(now).toISOString()} (Now)`);
    console.log(`   ğŸ¯ Pool: ${poolId}`);
    console.log(`   ğŸ“Š Events: All event types`);
    console.log(`   ğŸ“¦ Batch: 1000 events/request`);
    console.log(`   ğŸ“ Files: 200 events/file`);
    console.log('');

    if (futureStartTime >= now) {
        console.log('âœ… No new data needed - existing data is up to date');
        return;
    }

    const fetcher = new SuiEventFetcher({
        rpcUrl: 'https://fullnode.mainnet.sui.io:443',
        poolId: poolId,
        eventTypes: [
            EventType.Swap,
            EventType.AddLiquidity,
            EventType.RemoveLiquidity,
            EventType.RepayFlashSwap,
            EventType.CreatePool,
            EventType.OpenPosition
        ],
        startTime: futureStartTime,
        endTime: now,
        batchSize: 1000,
        outputDir: './data_future',
        filePrefix: 'future_'
    });

    const startTime = Date.now();

    try {
        console.log('ğŸš€ Starting future data collection...');
        console.log('âš ï¸  This should be relatively quick. Progress will be logged.\n');

        const pages = await fetcher.fetchAllEvents();

        const duration = (Date.now() - startTime) / 1000;

        // Count results
        const outputDir = './data_future';
        let fileCount = 0;
        let totalEvents = 0;
        let totalSize = 0;

        if (fs.existsSync(outputDir)) {
            const files = fs.readdirSync(outputDir).filter((f: string) => f.startsWith('future_'));
            fileCount = files.length;

            for (const file of files) {
                const filePath = `${outputDir}/${file}`;
                const stats = fs.statSync(filePath);
                totalSize += stats.size;

                const content = JSON.parse(fs.readFileSync(filePath, 'utf-8'));
                totalEvents += content.data.reduce((sum: number, tx: any) => sum + tx.events.length, 0);
            }
        }

        console.log('\nğŸ‰ Future Data Collection Complete!');
        console.log('===================================');
        console.log(`â±ï¸  Total Duration: ${duration.toFixed(1)} seconds`);
        console.log(`ğŸ“Š Total Events: ${totalEvents.toLocaleString()}`);
        console.log(`ğŸ“ Total Files: ${fileCount.toLocaleString()}`);
        console.log(`ğŸ’¾ Total Size: ${(totalSize / 1024 / 1024).toFixed(2)} MB`);
        console.log(`ğŸš€ Average Speed: ${(totalEvents / duration).toFixed(0)} events/sec`);
        console.log(`ğŸ“ Output Directory: ${outputDir}`);

        // Instructions
        console.log('\nğŸ“‹ Data Status:');
        console.log('===============');
        console.log('âœ… Historical: ./data_historical/ (if exists)');
        console.log('âœ… Main: ./data_30_days/');
        console.log('âœ… Future: ./data_future/');
        console.log('ğŸ’¡ Run merge script to combine all data chronologically');

    } catch (error) {
        const partialDuration = (Date.now() - startTime) / 1000;
        console.error('\nâŒ Future collection failed:', error);
        console.log(`â±ï¸  Partial duration: ${partialDuration.toFixed(1)} seconds`);
    }
}

if (import.meta.main) {
    fetchFuture().catch(console.error);
}
